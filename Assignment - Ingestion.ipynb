{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f465d61-9cde-4982-ac91-adaa736771d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[79]: [FileInfo(path='s3://goldyyy-de-practice/Assignment_Files/Customer.xlsx', name='Customer.xlsx', size=89424, modificationTime=1727727077000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"s3://goldyyy-de-practice/Assignment_Files/Customer.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe5514be-51af-4cce-b47f-a5a07d2d0ef7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./Assignment - utilities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aecfefc-d3f6-4c9f-868e-caeb45d045dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "    import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d75984-dd85-4d08-9a56-ff0b738872d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"createProfitReport\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1160263-f5ce-491c-a199-5f746b592bf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ingest Product File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605e20f1-8cbf-49c5-82b0-7e0144701995",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Create Product Schema\n",
    "productSchema = StructType([\n",
    "    StructField(\"Product ID\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Sub-Category\", StringType(), True),\n",
    "    StructField(\"Product Name\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"Price per product\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "### Read Product File from Data Lake\n",
    "product_df = spark.read.format('csv')\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(productSchema) \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .load(\"s3://goldyyy-de-practice/Assignment_Files/Product.csv\")\n",
    "\n",
    "### Update Column Names\n",
    "productColumnMapping = {\"Product ID\": \"product_id\",\n",
    "                 \"Category\": \"category\",\n",
    "                 \"Sub-Category\": \"sub_category\",\n",
    "                 \"Product Name\": \"product_name\",\n",
    "                 \"State\": \"state\",\n",
    "                 \"Price Per Product\": \"price_per_product\"}\n",
    "\n",
    "product_renamed_df = renameColumns(product_df, productColumnMapping)\n",
    "\n",
    "\n",
    "### Add audit columns\n",
    "columnsWithValues = {\n",
    "    \"ingestion_date\": F.current_timestamp()\n",
    "}\n",
    "\n",
    "product_final_df = addColumns(product_renamed_df, columnsWithValues)\n",
    "\n",
    "\n",
    "### Save Product Data in Delta table\n",
    "filePath = \"dbfs:/user/raw/raw_product\"\n",
    "schema = \"raw\"\n",
    "tableName = \"raw_product\"\n",
    "saveDataInTable(product_final_df, filePath, schema, tableName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aecfd5b-a892-4955-ace2-4acd2f238a49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ingest Customer File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2dd29d-c4df-4f44-a805-cfa56a72b215",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Create Customer Schema\n",
    "customerSchema = StructType([\n",
    "    StructField(\"Customer ID\", StringType(), True),\n",
    "    StructField(\"Customer Name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"phone\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"Segment\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"Postal Code\", DoubleType(), True),\n",
    "    StructField(\"Region\", StringType(), True),\n",
    "])\n",
    "\n",
    "### Read Customer File from Data Lake\n",
    "customer_df = spark.read.format('com.crealytics.spark.excel') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(customerSchema) \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .load(\"s3://goldyyy-de-practice/Assignment_Files/Customer.xlsx\")\n",
    "\n",
    "### Update Column Names\n",
    "customerColumnMapping = {\"Customer ID\": \"customer_id\",\n",
    "                 \"Customer Name\": \"customer_name\",\n",
    "                 \"Segment\": \"segment\",\n",
    "                 \"Country\": \"country\",\n",
    "                 \"City\": \"city\",\n",
    "                 \"State\": \"state\",\n",
    "                 \"Postal Code\": \"postal_code\",\n",
    "                 \"Region\": \"region\"\n",
    "}\n",
    "\n",
    "customer_renamed_df = renameColumns(customer_df, customerColumnMapping)\n",
    "\n",
    "\n",
    "### Add audit columns\n",
    "columnsWithValues = {\n",
    "    \"ingestion_date\": F.current_timestamp()\n",
    "}\n",
    "\n",
    "customer_final_df = addColumns(customer_renamed_df, columnsWithValues)\n",
    "\n",
    "\n",
    "### Save Customer Data in Delta table\n",
    "filePath = \"dbfs:/user/raw/raw_customer\"\n",
    "schema = \"raw\"\n",
    "tableName = \"raw_customer\"\n",
    "saveDataInTable(customer_final_df, filePath, schema, tableName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68548ff9-d0f1-45b7-8b26-1efdefbef7b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ingest Orders File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75abb1f1-452a-4084-97fd-f2253d0733eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Create Orders schema\n",
    "orderSchema = StructType([\n",
    "    StructField(\"Row ID\", IntegerType(), True),\n",
    "    StructField(\"Order ID\", StringType(), True),\n",
    "    StructField(\"Order Date\", StringType(), True),\n",
    "    StructField(\"Ship Date\", StringType(), True),\n",
    "    StructField(\"Ship Mode\", StringType(), True),\n",
    "    StructField(\"Customer ID\", StringType(), True),\n",
    "    StructField(\"Product ID\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"Price\", StringType(), True),\n",
    "    StructField(\"Discount\", DoubleType(), True),\n",
    "    StructField(\"Profit\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "### Read Orders file from data lake\n",
    "orders_df = spark.read.option(\"multiline\", \"true\").schema(orderSchema).json(\"s3://goldyyy-de-practice/Assignment_Files/Order.json\")\n",
    "\n",
    "### Data pre-processing\n",
    "\n",
    "orders_formatted_df = orders_df.withColumn(\"Cleaned Price\", F.regexp_replace(F.col(\"Price\"), \"%\", \"\").cast(DoubleType())).withColumn(\"order_date\", F.to_date(\"Order Date\", 'd/m/yyyy')).withColumn(\"ship_date\", F.to_date(\"Ship Date\", 'd/m/yyyy'))\n",
    "\n",
    "### Drop columns that are not required\n",
    "columnsToDrop = [\"Ship Date\", \"Order Date\", \"Price\"]\n",
    "orders_cleaned_df = dropColumns(orders_formatted_df, columnsToDrop)\n",
    "\n",
    "### Update Column Names\n",
    "ordersColumnMapping = {\n",
    "    \"Row ID\": \"row_id\",\n",
    "    \"Order ID\": \"order_id\",\n",
    "    \"Ship Mode\": \"ship_mode\",\n",
    "    \"Customer ID\": \"customer_id\",\n",
    "    \"Product ID\": \"product_id\",\n",
    "    \"Quantity\": \"quantity\",\n",
    "    \"Cleaned Price\": \"price\",\n",
    "    \"Discount\": \"discount\",\n",
    "    \"Profit\": \"profit\"\n",
    "}\n",
    "\n",
    "orders_renamed_df = renameColumns(orders_cleaned_df, ordersColumnMapping)\n",
    "\n",
    "\n",
    "### Add audit columns\n",
    "columnsWithValues = {\n",
    "    \"ingestion_date\": F.current_timestamp()\n",
    "}\n",
    "\n",
    "orders_final_df = addColumns(orders_renamed_df, columnsWithValues)\n",
    "\n",
    "\n",
    "### Save Customer Data in Delta table\n",
    "filePath = \"dbfs:/user/raw/raw_orders\"\n",
    "schema = \"raw\"\n",
    "tableName = \"raw_orders\"\n",
    "saveDataInTable(orders_final_df, filePath, schema, tableName)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1783702652565901,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment - Ingestion",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
